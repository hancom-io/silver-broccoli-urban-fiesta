---
title: 쉽게 풀어쓴 자연어처리 NLP(Natural Language Processing)
author: 김건우
author_id: hnc-keonwookim
tag: 
- AI
- NLP
- 자연어처리
- 인공지능
excerpt: 인공지능 자연어처리에 대해 쉽게 알아보자.
---

# 자연어처리 NLP

<br />

### 인공지능에서 자연어처리가 어떤 기술이고 어떻게 개발을 진행하고 있는지 잘 모르는 분들을 위해 이해하기 쉽고 재밌게 글을 적어봤습니다. 이번 포스팅에서는 자연어처리가 무엇인지 한번 알아보는 시간을 가져보도록 하겠습니다.

<br />
<br />

## 1. 인공지능에서 자연어 처리는?
> !["ai-background-1"]({{ site.assets }}/2021/2021-07-19-ai-background-1.jpg){:width="700px"}

<br />
우리는 몇 년 전부터 “4차 산업혁명이 도래했다.”, “인공지능이 세계를 지배한다.”, “인공지능이 우리의 삶의 질을 바꿀 것이다.”라는 문구를 뉴스, 신문기사, 서점에서의 서적 표지만 보더라도 쉽게 접할 수 있었습니다.

<br />
음성인식(STT, Speech-To-Text), 음성합성(TTS, Text-To-Speech) 분야에서는 인공지능 스피커가 보편화되면서 사람들에게 편리성을 제공해줬고, Siri나 빅스비로 스케줄 관리, 전화 걸기, 카페에서 좋은 노래가 나오면 어떤 노래인지 찾는 등의 기능을 사용하며 삶의 질이 향상되는 것을 피부로 느꼈을 것입니다.

<br />
영상인식으로는 카메라의 필터 보정이나 얼굴인식을 통해 다양한 테마들을 설정해 재밌는 사진을 찍어 친구들과 공유하기도 했고 차량의 전방 충돌 방지, 차로 이탈 방지 등을 통해 안전한 주행을 할 수 있게 되었습니다. 이렇게 해가 거듭될수록 인공지능은 우리의 삶에 천천히 녹아들고 있음은 자명해 보입니다.

<br />
일반 사람들에게 AI 인공지능에 대해 물어본다면 당연하게도 우리와 밀접해있는 음성인식, 영상인식이 먼저 나올 것이라 생각됩니다. 그러나 이 외에도 다른 여러 분야의 인공지능 기술이 다양한 부분에서 우리를 돕고 있는데 자연어처리, 챗봇, 추천 시스템, 번역, 자율 주행 등의 많은 기술들이 보이지 않게 우리에게 많은 도움을 주고 있다고 할 수 있습니다. 이번 포스팅에서는 사람들에게 익숙하지 않은 자연어처리기술에 대해 한번 이야기해 보도록 하겠습니다.
<br />
<br />

> !["ai-background-2"]({{ site.assets }}/2021/2021-07-19-ai-background-2.jpg){:width="700px"}
>
> 출처 : 인공지능신문(http://www.aitimes.kr)

<br />
자연어처리에서 자연어(natural language)는 사람이 사용하는 모든 언어를 말하며, 자연어처리(natural language processing)는 컴퓨터가 자연어의 의미를 분석하여 읽고 처리할 수 있도록 하는 작업을 말합니다. 오래전부터 사람의 언어를 컴퓨터가 이해할 수 있도록 많은 연구들이 이루어져 왔지만 모든 인공지능 분야가 그렇듯 하드웨어 성능의 제한, 정제된 데이터의 부족 등의 다양한 이유로 연구에 많은 어려움이 있었습니다.
<br />
<br />

> !["ai-background-3"]({{ site.assets }}/2021/2021-07-19-ai-background-3.jpg){:width="700px"}

<br />
그러나 최근에는 고성능의 CPU, GPU, 메모리로 컴퓨터의 빠른 처리 속도 그리고 스마트폰이 개발되고 빠른 네트워크 통신 속도로 인터넷에 많은 데이터가 축적되면서 인공지능 연구와 개발이 수월하게 되었고 자연어처리 개발 또한 많은 발전을 이룰 수 있게 되었습니다.
<br />
자연어처리를 하기 위해서는 자연어의 특성을 잘 알고 있어야 합니다. 각각의 언어마다 가진 고유의 특성들이 있고 언어마다 형태가 다르기 때문에 컴퓨터가 이해하기 쉽게 잘 정리해서 알려줘야 좋은 성능의 인공지능 모델이 나올 수 있습니다.
<br />
자연어처리는 잘 드러나진 않지만 정말 많은 곳에서 사용되고 있습니다. 음성인식, 문장 분리, 내용 요약, 질문 분류, 질문 생성, 질의응답, 챗봇, 번역, 맞춤법 검사, 텍스트 분류, 비식별화 등 언어가 사용되는 모든 곳에 사용될 수 있습니다. 그렇기 때문에 한국의 인공지능 기술 발전을 위해 자연어 처리는 인공지능에서 필수 연구 분야이며 앞으로도 많은 진전이 필요한 분야입니다.
<br />
<br />

## 2. 한국어와 언어모델
예전 딥러닝이 있기 전 자연어처리는 확률에 기반한 언어 모델을 사용하였습니다. 확률 기반이란 우리가 사용하는 언어가 보통 문법에 기반하여 사용하기 때문에 “주어” 다음은 “서술어” 가 오겠지 라고 판단하는 것을 의미합니다.

영어의 경우 1 형식인지 5 형식인지는 주어 동사 목적어 보어의 위치에 대한 정보만 알면 주어 다음에 어떤 단어가 올지 미리 예측이 가능하지만, 한국어는 어순이 크게 중요하지 않고 문장의 앞 뒤 맥락에 의해 생략되는 단어가 있음에도 의미 전달이 가능합니다. 

예를 들어 보면 다음과 같습니다.

1. "나는 학교에서 공부를 한다."
2. "학교에서 나는 공부를 한다."
3. "학교에서 공부를 한다."
4. "나는 공부를 한다 학교에서."
5. "나는공부를학교에서한다."

<br />
예시처럼 한국어는 단어 예측이 다른 언어보다 훨씬 까다롭기 때문에 확률에 기반한 한국어 언어 모델 개발에 어려움이 있습니다. 또한, 한국어는 5번처럼 띄어쓰기를 하지 않아도 의미 전달이 되기 때문에 데이터를 만들 때 문장의 띄어쓰기가 제대로 지켜지지 않는 데이터가 많아 학습 데이터를 만드는 데에도 많은 노력과 시간이 필요합니다. 띄어쓰기가 제대로 되지 않으면 데이터 전처리에서 제대로 된 형태소로 분리되지 않고 잘못된 데이터가 학습 데이터로 들어가면 좋은 성능의 모델이 나오지 않기 때문에 한국어 언어 모델 개발이 다른 언어 모델보다 개발이 더 어렵다고 할 수 있습니다.
<br />
<br />

## 3. 자연어처리 학습 데이터는 어떤 데이터인가?

<br />
자연어처리기술에서 사용하는 학습 데이터는 도메인에 따라 다양한 형태로 데이터를 만들어 학습시킬 수 있습니다. 그러나 데이터도 사람들이 많이 사용하는 데이터나 학습에 필수적으로 들어가야 하는 데이터나 오랜 기간 축적해야하는 데이터의 경우에는 표준은 정해 여러사람들이 데이터를 함께 만들고 연구하면 더 좋은 데이터가 나올 것입니다. 그래서 한국정보통신기술협회에서는 TTA 표준으로 여러 기관에서 사용한 품사 태그 세트를 바탕으로 “형태소 태깅 말뭉치 작성용 품사 태그 세트”를 작성하여 말뭉치 데이터의 재사용성 및 공유를 가능하게 하였습니다. 이 외에도 개체명 인식, 동음이의어/다의어 분석, 의존 구문분석, 의미역 인식 등 컴퓨터가 한국어의 고유 의미, 문맥 등을 파악할 수 있도록 정제된 데이터들이 데이터 표준에 따라 만들어지고 있으며, 이런 연구 개발자들 간의 약속을 통해 더 질 좋은 한국어 형태소 분석 데이터가 만들어져 한국어 자연어처리 모델 성능도 나날이 좋아지고 있는 것 같습니다.
<br />
<br />

## 4. 언어모델의 발전

<br />

> !["turing-test"]({{ site.assets }}/2021/2021-07-19-turing-test.jpg){:width="700px"}
>
> 출처: https://slideplayer.com/slide/6019950/

<br />
1950년에 엘런 튜링에 의해 개발된 Turing test가 있는데 이 테스트는 인간 평가자가 인간과 같은 반응을 일으키도록 설계된 기계 사이의 자연 언어 대화를 판단하는 테스트로 평가자가 기계와 인간을 확실하게 구분할 수 없는 경우, 그 기계는 Turing test에 합격하였다고 이야기합니다[1]. 이 실험은 "기계가 생각할 수 있는가?"라는 튜링의 질문에서 시작된 실험인데 이 실험처럼 자연어처리 개발의 궁극적인 목적은 컴퓨터가 인간이 의도한 질문을 이해하고 사람처럼 답을 제시하고 행동하는 것입니다.
<br />
2015년까지만 하더라도 한국어 자연어처리에 대한 인식은 좋지 못했습니다. 제대로 된 데이터도 없었고 규칙 기반이거나 통계에 기반한 모델이었기 때문에 좋은 성능의 언어 모델을 기대하기 힘들었습니다. 그러나 2017년부터 transformer, GPT에 이어 BERT 딥러닝 인공신경망 언어모델이 발표되면서부터 자연어처리 언어 모델이 빠른 발전을 하게 되고 Human Performance를 훨씬 뛰어넘는 BERT기반 모델들이 많이 개발되었습니다.
<br />
<br />

## 5. 언어모델학습
<br />
자연어처리기술에서 사용되는 언어 모델을 학습하기 위해선 우선 특성에 맞는 데이터가 있어야 합니다. 양질의 데이터가 많으면 많을수록 좋을 수도 있지만 데이터가 한쪽으로 치우쳐 있으면 좋은 모델이 될 수 없기 때문에 학습 데이터에 대한 전처리 과정이 꼭 필요합니다. 모델 특성에 맞게 학습될 수 있도록 데이터 전처리해줘야 하기 때문에 다양한 전처리과정이 어떻게 처리하냐에 따라서도 성능에 많은 영향을 미칠 수 있습니다. 텍스트 토큰화 과정이나, 
<br />
<br />

> !["character-count"]({{ site.assets }}/2021/2021-07-19-character-count.jpg){:width="700px"}

<br />
데이터가 골고루 분포될 수 있도록 너무 문장이 길거나 짧은 데이터를 제거하거나 자를 수도 있고, 
<br />
<br />

> !["bag-of-words"]({{ site.assets }}/2021/2021-07-19-bag-of-words.jpg){:width="700px"}
>
> 출처: https://slideplayer.com/slide/7073400/

<br />
문장을 인코딩 과정을 거쳐 0과 1로 표현하는 과정 또한 전처리에 포함되는 내용입니다. 이런 과정들을 거쳐 만들어진 학습 데이터를 언어 모델에 학습시키는 것이 자연어처리 개발의 일반적인 내용이라고 할 수 있습니다.
<br />
<br />

## 마치며
<br />
이번 포스팅은 인공지능 자연어처리에 대한 내용을 쉽게 이해하실 수 있도록 글을 작성해봤습니다. 
<br />
다음 포스팅에서는 자연어처리에 들어가는 여러과정들을 조금 더 세부적으로 소개하고 설명해보도록 하겠습니다~ :)
<br />
<br />

---
### **reference**
* [1] https://en.wikipedia.org/wiki/Turing_test